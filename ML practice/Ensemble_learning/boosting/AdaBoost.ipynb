{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  label\n",
       "0   1   5      1\n",
       "1   2   3      1\n",
       "2   3   6      0\n",
       "3   4   8      1\n",
       "4   5   1      0\n",
       "5   6   9      1\n",
       "6   6   5      0\n",
       "7   7   8      1\n",
       "8   9   9      0\n",
       "9   9   2      0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "     \n",
    "\n",
    "df = pd.DataFrame()\n",
    "     \n",
    "\n",
    "df['X1'] = [1,2,3,4,5,6,6,7,9,9]\n",
    "df['X2'] = [5,3,6,8,1,9,5,8,9,2]\n",
    "df['label'] = [1,1,0,1,0,1,0,1,0,0]\n",
    "     \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='X1', ylabel='X2'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(x=df['X1'],y=df['X2'],hue=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_row_weights(row,alpha):\n",
    "  if row['label'] == row['y_pred']:\n",
    "    return row['weights'] * np.exp(-alpha)\n",
    "  else:\n",
    "    return row['weights'] * np.exp(alpha)\n",
    "     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_model_weight(error):\n",
    "\n",
    "  return 0.5*np.log((1-error)/(error+0.0000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_dataset(df):\n",
    "\n",
    "  indices = []\n",
    "\n",
    "  for i in range(df.shape[0]):\n",
    "    a = np.random.random()\n",
    "    for index,row in df.iterrows():\n",
    "      if row['cumsum_upper'] > a and a > row['cumsum_lower']:\n",
    "        indices.append(index)\n",
    "  return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_decision_trump(df):\n",
    "    index_values = create_new_dataset(df)\n",
    "    next_df = df.iloc[index_values,[0,1,2,3]]\n",
    "    return next_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df):  \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=1)\n",
    "    X = df.iloc[:,0:2].values\n",
    "    y = df.iloc[:,2].values\n",
    "    dt.fit(df.iloc[:,0:2],df.iloc[:,2])\n",
    "    df['y_pred'] = dt.predict(df.iloc[:,0:2])\n",
    "    error = np.sum(df['weights'] * (df['y_pred'] != df['label'])) / np.sum(df['weights'])\n",
    "    return error,dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class ada_boosting:\n",
    "    alpha=[]\n",
    "    estimators=None\n",
    "    model=[]\n",
    "    def fit(self,df,n_estimators):\n",
    "        flag=0\n",
    "        i=0\n",
    "        df['weights'] = 1/df.shape[0]\n",
    "        self.estimators=n_estimators\n",
    "        while n_estimators!=flag:\n",
    "            error,dt=prediction(df)\n",
    "            self.model.append(dt)\n",
    "            \n",
    "            alph = calculate_model_weight(error)\n",
    "            self.alpha.append(alph)\n",
    "            \n",
    "            df['weights'] *= np.exp(-alph * df['label'] * df['y_pred'])\n",
    "            df['weights'] /= df['weights'].sum()\n",
    "            \n",
    "            \n",
    "            def update_row_weights(row):\n",
    "                if row['label'] == row['y_pred']:\n",
    "                    return row['weights'] * np.exp(-alph)\n",
    "                else:\n",
    "                    return row['weights'] * np.exp(alph)\n",
    "                \n",
    "            df['updated_weights'] = df.apply(update_row_weights,axis=1)\n",
    "            \n",
    "            \n",
    "            df['nomalized_weights'] = df['updated_weights']/df['updated_weights'].sum()\n",
    "            \n",
    "            df['cumsum_upper'] = np.cumsum(df['nomalized_weights'])\n",
    "            \n",
    "\n",
    "            df['cumsum_lower'] = df['cumsum_upper'] - df['nomalized_weights']\n",
    "            print(df)\n",
    "            df=next_decision_trump(df)\n",
    "            flag = flag+1\n",
    "  \n",
    "    def pred(self,n1,n2,dt):\n",
    "        flag=0\n",
    "        while self.estimators != flag:\n",
    "            query = np.array([n1,n2]).reshape(1,2)\n",
    "            result=self.model[flag].predict(query)\n",
    "            if result ==0:\n",
    "                result=-1\n",
    "            alpha = 0\n",
    "            alpha=alpha+(self.alpha[flag]*result)\n",
    "            \n",
    "            flag = flag+1\n",
    "        print(alpha)    \n",
    "        f_result=np.sign(alpha)\n",
    "        if f_result==-1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class AdaBoosting:\n",
    "    def __init__(self):\n",
    "        self.alpha = []  # Store model weights\n",
    "        self.estimators = 0  # Number of estimators\n",
    "        self.models = []  # Store weak learners\n",
    "\n",
    "    def fit(self, df, n_estimators):\n",
    "        \"\"\"Train AdaBoost classifier using decision stumps.\"\"\"\n",
    "        self.estimators = n_estimators\n",
    "        df['weights'] = 1 / df.shape[0]  # Initialize weights\n",
    "        \n",
    "        for _ in range(n_estimators):\n",
    "            # Train weak classifier\n",
    "            dt = DecisionTreeClassifier(max_depth=1)\n",
    "            dt.fit(df.iloc[:, :-2], df['label'], sample_weight=df['weights'])\n",
    "            \n",
    "            # Get predictions and compute error\n",
    "            df['y_pred'] = dt.predict(df.iloc[:, :-2])\n",
    "            error = np.sum(df['weights'] * (df['y_pred'] != df['label'])) / np.sum(df['weights'])\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if error == 0:\n",
    "                error = 1e-10\n",
    "            \n",
    "            alph = 0.5 * np.log((1 - error) / error)\n",
    "            # Compute alpha (model weight)\n",
    "            self.alpha.append(alph)\n",
    "            self.models.append(dt)\n",
    "            \n",
    "            # Update weights\n",
    "            df['weights'] *= np.exp(-alph * df['label'] * df['y_pred'])\n",
    "            df['weights'] /= df['weights'].sum()  # Normalize weights\n",
    "            print(df)\n",
    "            \n",
    "    def predict(self, n1, n2):\n",
    "        \"\"\"Make predictions using the trained AdaBoost model.\"\"\"\n",
    "        query = np.array([n1, n2]).reshape(1, -1)\n",
    "        final_prediction = 0\n",
    "        \n",
    "        for alpha, model in zip(self.alpha, self.models):\n",
    "            pred = model.predict(query)[0]\n",
    "            final_prediction += alpha * (1 if pred == 1 else -1)\n",
    "        \n",
    "        return 1 if final_prediction >= 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.model[1].predict([[5,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "     \n",
    "\n",
    "df['X1'] = [1,2,3,4,5,6,6,7,9,9]\n",
    "df['X2'] = [5,3,6,8,1,9,5,8,9,2]\n",
    "df['label'] = [1,1,0,1,0,1,0,1,0,0]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  label   weights  y_pred\n",
      "0   1   5      1  0.079129       1\n",
      "1   2   3      1  0.079129       1\n",
      "2   3   6      0  0.120871       1\n",
      "3   4   8      1  0.079129       1\n",
      "4   5   1      0  0.120871       0\n",
      "5   6   9      1  0.079129       1\n",
      "6   6   5      0  0.120871       1\n",
      "7   7   8      1  0.079129       1\n",
      "8   9   9      0  0.120871       1\n",
      "9   9   2      0  0.120871       0\n",
      "   X1  X2  label   weights  y_pred\n",
      "0   1   5      1  0.000001       1\n",
      "1   2   3      1  0.000001       1\n",
      "2   3   6      0  0.199999       0\n",
      "3   4   8      1  0.000001       1\n",
      "4   5   1      0  0.199999       0\n",
      "5   6   9      1  0.000001       1\n",
      "6   6   5      0  0.199999       0\n",
      "7   7   8      1  0.000001       1\n",
      "8   9   9      0  0.199999       0\n",
      "9   9   2      0  0.199999       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-11       1\n",
      "1   2   3      1  1.309307e-11       1\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-11       1\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-11       1\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-11       1\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-16       1\n",
      "1   2   3      1  1.309307e-16       1\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-16       1\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-16       1\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-16       1\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       1\n",
      "1   2   3      1  1.309307e-21       1\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       1\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       1\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       1\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       0\n",
      "1   2   3      1  1.309307e-21       0\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       0\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       0\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       0\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       0\n",
      "1   2   3      1  1.309307e-21       0\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       0\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       0\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       0\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       0\n",
      "1   2   3      1  1.309307e-21       0\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       0\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       0\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       0\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       0\n",
      "1   2   3      1  1.309307e-21       0\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       0\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       0\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       0\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n",
      "   X1  X2  label       weights  y_pred\n",
      "0   1   5      1  1.309307e-21       0\n",
      "1   2   3      1  1.309307e-21       0\n",
      "2   3   6      0  2.000000e-01       0\n",
      "3   4   8      1  1.309307e-21       0\n",
      "4   5   1      0  2.000000e-01       0\n",
      "5   6   9      1  1.309307e-21       0\n",
      "6   6   5      0  2.000000e-01       0\n",
      "7   7   8      1  1.309307e-21       0\n",
      "8   9   9      0  2.000000e-01       0\n",
      "9   9   2      0  2.000000e-01       0\n"
     ]
    }
   ],
   "source": [
    "AB=AdaBoosting()\n",
    "model=AB.fit(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "0   1   5      1      0.1       1         0.065465           0.071429   \n",
      "1   2   3      1      0.1       1         0.065465           0.071429   \n",
      "2   3   6      0      0.1       1         0.152752           0.166667   \n",
      "3   4   8      1      0.1       1         0.065465           0.071429   \n",
      "4   5   1      0      0.1       0         0.065465           0.071429   \n",
      "5   6   9      1      0.1       1         0.065465           0.071429   \n",
      "6   6   5      0      0.1       1         0.152752           0.166667   \n",
      "7   7   8      1      0.1       1         0.065465           0.071429   \n",
      "8   9   9      0      0.1       1         0.152752           0.166667   \n",
      "9   9   2      0      0.1       0         0.065465           0.071429   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "0      0.071429      0.000000  \n",
      "1      0.142857      0.071429  \n",
      "2      0.309524      0.142857  \n",
      "3      0.380952      0.309524  \n",
      "4      0.452381      0.380952  \n",
      "5      0.523810      0.452381  \n",
      "6      0.690476      0.523810  \n",
      "7      0.761905      0.690476  \n",
      "8      0.928571      0.761905  \n",
      "9      1.000000      0.928571  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "9   9   2      0      0.1       0             0.05             0.0625   \n",
      "0   1   5      1      0.1       1             0.05             0.0625   \n",
      "8   9   9      0      0.1       0             0.05             0.0625   \n",
      "4   5   1      0      0.1       0             0.05             0.0625   \n",
      "7   7   8      1      0.1       0             0.20             0.2500   \n",
      "8   9   9      0      0.1       0             0.05             0.0625   \n",
      "4   5   1      0      0.1       0             0.05             0.0625   \n",
      "3   4   8      1      0.1       1             0.05             0.0625   \n",
      "6   6   5      0      0.1       0             0.05             0.0625   \n",
      "2   3   6      0      0.1       1             0.20             0.2500   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "9        0.0625        0.0000  \n",
      "0        0.1250        0.0625  \n",
      "8        0.1875        0.1250  \n",
      "4        0.2500        0.1875  \n",
      "7        0.5000        0.2500  \n",
      "8        0.5625        0.5000  \n",
      "4        0.6250        0.5625  \n",
      "3        0.6875        0.6250  \n",
      "6        0.7500        0.6875  \n",
      "2        1.0000        0.7500  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.033333           0.055556   \n",
      "7   7   8      1      0.1       1         0.033333           0.055556   \n",
      "8   9   9      0      0.1       0         0.033333           0.055556   \n",
      "3   4   8      1      0.1       1         0.033333           0.055556   \n",
      "8   9   9      0      0.1       0         0.033333           0.055556   \n",
      "7   7   8      1      0.1       1         0.033333           0.055556   \n",
      "4   5   1      0      0.1       1         0.300000           0.500000   \n",
      "7   7   8      1      0.1       1         0.033333           0.055556   \n",
      "7   7   8      1      0.1       1         0.033333           0.055556   \n",
      "8   9   9      0      0.1       0         0.033333           0.055556   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8      0.055556      0.000000  \n",
      "7      0.111111      0.055556  \n",
      "8      0.166667      0.111111  \n",
      "3      0.222222      0.166667  \n",
      "8      0.277778      0.222222  \n",
      "7      0.333333      0.277778  \n",
      "4      0.833333      0.333333  \n",
      "7      0.888889      0.833333  \n",
      "7      0.944444      0.888889  \n",
      "8      1.000000      0.944444  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "7   7   8      1      0.1       1         0.000032                0.1   \n",
      "7   7   8      1      0.1       1         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "7   7   8      1      0.1       1         0.000032                0.1   \n",
      "7   7   8      1      0.1       1         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "7   7   8      1      0.1       1         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "7           0.1           0.0  \n",
      "7           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "7           0.5           0.4  \n",
      "7           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "7           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n",
      "   X1  X2  label  weights  y_pred  updated_weights  nomalized_weights  \\\n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "8   9   9      0      0.1       0         0.000032                0.1   \n",
      "\n",
      "   cumsum_upper  cumsum_lower  \n",
      "8           0.1           0.0  \n",
      "8           0.2           0.1  \n",
      "8           0.3           0.2  \n",
      "8           0.4           0.3  \n",
      "8           0.5           0.4  \n",
      "8           0.6           0.5  \n",
      "8           0.7           0.6  \n",
      "8           0.8           0.7  \n",
      "8           0.9           0.8  \n",
      "8           1.0           0.9  \n"
     ]
    }
   ],
   "source": [
    "ada=ada_boosting()\n",
    "model=ada.fit(df,10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoosting.predict() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[259], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: AdaBoosting.predict() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "AB.predict(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.05904783]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.pred(4,8,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>label</th>\n",
       "      <th>weights</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  label  weights  y_pred\n",
       "0   1   5      1      0.1       1\n",
       "1   2   3      1      0.1       1\n",
       "2   3   6      0      0.1       0\n",
       "3   4   8      1      0.1       0\n",
       "4   5   1      0      0.1       0\n",
       "5   6   9      1      0.1       0\n",
       "6   6   5      0      0.1       0\n",
       "7   7   8      1      0.1       0\n",
       "8   9   9      0      0.1       0\n",
       "9   9   2      0      0.1       0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
